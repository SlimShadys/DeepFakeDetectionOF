{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U tqdm gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies loaded.\n",
      "===================================================\n",
      "Cuda available: True\n",
      "GPU: NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "Total memory: 6.0 GB\n",
      "===================================================\n",
      "Torch version: 2.0.1+cu118\n",
      "Torchvision version: 0.15.2+cu118\n",
      "===================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import gdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print('Dependencies loaded.')\n",
    "print(\"===================================================\")\n",
    "\n",
    "if(torch.cuda.is_available()):\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('Cuda available: {}'.format(torch.cuda.is_available()))\n",
    "    print(\"GPU: \" + torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    print(\"Total memory: {:.1f} GB\".format((float(torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)))))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('Cuda not available, so using CPU. Please consider switching to a GPU runtime before running the notebook!')\n",
    "    \n",
    "print(\"===================================================\")\n",
    "print(F\"Torch version: {torch.__version__}\")\n",
    "print(F\"Torchvision version: {torchvision.__version__}\")\n",
    "print(\"===================================================\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Download\n",
    "ID = '1wYzBpucuU_RPMebUrWi2TH3Mfz-ykBGl' # PWC-Net | Real & Face2Face\n",
    "output = 'Dataset.zip'\n",
    "\n",
    "datasetDirectory = \"Dataset\"\n",
    "if not (os.path.exists(datasetDirectory)):\n",
    "  os.makedirs(datasetDirectory)\n",
    "\n",
    "dataset_url = 'https://drive.google.com/uc?id=' + ID + '&export=download&confirm=t'\n",
    "gdown.download(dataset_url, output, quiet=False)\n",
    "\n",
    "with zipfile.ZipFile(output) as zf:\n",
    "    for member in tqdm(zf.infolist(), desc='Extracting '):\n",
    "        try:\n",
    "            zf.extract(member, datasetDirectory)\n",
    "        except zipfile.error as e:\n",
    "            pass\n",
    "\n",
    "print('Deleting the previous downloaded zip.')\n",
    "os.remove('Dataset.zip')\n",
    "print('Done.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (ResNet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# Replace the last fully connected layer\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(nn.Linear(num_features, 1, device=device),\n",
    "                         nn.Sigmoid())\n",
    "\n",
    "# Freeze pre-trained layers\n",
    "for n, p in model.named_parameters():\n",
    "    if(n.startswith(\"layer4\") or n.startswith(\"fc\")):\n",
    "        p.requires_grad = True\n",
    "    else:\n",
    "        p.requires_grad = False\n",
    "    #print(F\"Parameter: {n} | Requires grad: {p.requires_grad}\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(modelPath, isCheckpoint=True):\n",
    "    bestAcc = 0.0\n",
    "    startEpoch = 1\n",
    "\n",
    "    if(isCheckpoint):\n",
    "        print(\"You specified a pre-loading directory for a checkpoint.\")\n",
    "    else:\n",
    "        print(\"You specified a pre-loading directory for a model.\")\n",
    "\n",
    "    if os.path.isfile(modelPath):\n",
    "        print(\"=> Loading model '{}'\".format(modelPath))\n",
    "        modelLoaded = torch.load(modelPath)\n",
    "\n",
    "        # State & Optimizer\n",
    "        model.load_state_dict(modelLoaded[\"state_dict\"], strict=False)\n",
    "\n",
    "        # Best validations\n",
    "        try:\n",
    "            bestAcc = modelLoaded[\"best_val\"]\n",
    "            print(F\"\\t- Best validation accuracy: {bestAcc:.5f}\")\n",
    "        except:\n",
    "            print(\"\\t- No best validation accuracy present in this model\")\n",
    "            pass\n",
    "\n",
    "        if(isCheckpoint):\n",
    "            optimizer.load_state_dict(modelLoaded[\"optimizer\"])\n",
    "\n",
    "            # Starting epoch\n",
    "            try:\n",
    "                startEpoch = modelLoaded[\"epoch\"]\n",
    "                print(F\"\\t- Starting from epoch n.{startEpoch}\")\n",
    "            except:\n",
    "                print(\"\\t- No starting epoch present in this model\")\n",
    "                pass\n",
    "\n",
    "        if(isCheckpoint):\n",
    "            print(\"Checkpoint loaded successfully.\")\n",
    "        else:\n",
    "            print(\"model loaded successfully.\")\n",
    "    else:\n",
    "        if(isCheckpoint):\n",
    "            print(\"=> No checkpoint found at '{}'\".format(modelPath))\n",
    "        else:\n",
    "            print(\"=> No model found at '{}'\".format(modelPath))\n",
    "\n",
    "        print(\"Are you sure the directory / model exist? Exiting..\")\n",
    "        exit(0)\n",
    "\n",
    "    print(\"===================================================\")\n",
    "    return bestAcc, startEpoch\n",
    "\n",
    "def saveModel(state, is_best):\n",
    "    if is_best:\n",
    "        path = str(savePath) + '/best/' + F'resnet50_best_epoch-{state[\"epoch\"]}_accT-{state[\"train_val\"]:.5f}_accV-{state[\"best_val\"]:.5f}.pt'\n",
    "    else:\n",
    "        path = str(savePath) + '/checkpoint/' + F'resnet50_checkpoint_epoch-{state[\"epoch\"]}_accT-{state[\"train_val\"]:.5f}_accV-{state[\"best_val\"]:.5f}.pt'\n",
    "    torch.save(state, path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters of the training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()  # Cross-entropy loss for classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # Optimizer for training the last layer\n",
    "epochs = 50\n",
    "batchSize = 64\n",
    "useFullDataset = False\n",
    "# ============================================== #\n",
    "savePath = os.path.join(\"save_path\", \"resnet50\")\n",
    "if not(os.path.exists(savePath)):\n",
    "    os.makedirs(savePath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "transformTrain = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(0.33),\n",
    "    transforms.CenterCrop(286),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transformsTest = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define paths for train_dir and test_dir according to split perfomed on OFs dataset\n",
    "train_dir = os.path.join(\"Dataset\", \"train\")\n",
    "test_dir = os.path.join(\"Dataset\", \"test\")\n",
    "\n",
    "# Load the ImageFolder datasets for train and test directories\n",
    "train_dataset = ImageFolder(root=train_dir, transform=transformTrain)\n",
    "test_dataset = ImageFolder(root=test_dir, transform=transformsTest)\n",
    "\n",
    "if not useFullDataset:\n",
    "\n",
    "    # Define the total number of frames required\n",
    "    total_frames = 85800\n",
    "\n",
    "    # Define the desired ratio between train and test sets\n",
    "    train_ratio = 0.8  # 80% for training, 20% for testing\n",
    "\n",
    "    # Calculate the number of frames for training and testing based on the desired ratio\n",
    "    train_frames = int(total_frames * train_ratio)\n",
    "\n",
    "    # Shuffle the indices of the train dataset\n",
    "    train_indices = list(range(len(train_dataset)))\n",
    "    random.shuffle(train_indices)\n",
    "\n",
    "    # Select the desired number of frames for training\n",
    "    selected_train_indices = train_indices[:train_frames]\n",
    "\n",
    "    # Calculate the remaining number of frames for testing\n",
    "    remaining_frames = total_frames - train_frames\n",
    "\n",
    "    # Check if the remaining frames exceed the number of samples in the test dataset\n",
    "    if remaining_frames > len(test_dataset):\n",
    "        remaining_frames = len(test_dataset)\n",
    "\n",
    "    # Shuffle the indices of the test dataset\n",
    "    test_indices = list(range(len(test_dataset)))\n",
    "    random.shuffle(test_indices)\n",
    "\n",
    "    # Select the desired number of frames for testing\n",
    "    selected_test_indices = test_indices[:remaining_frames]\n",
    "\n",
    "    # Create subsets of the train and test datasets using the selected indices\n",
    "    train_dataset = torch.utils.data.Subset(train_dataset, selected_train_indices)\n",
    "    test_dataset = torch.utils.data.Subset(test_dataset, selected_test_indices)\n",
    "\n",
    "# Create data loaders for the train and test subsets\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batchSize, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batchSize, shuffle=False)\n",
    "\n",
    "# Check the updated number of frames in each loader\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(\"===================================================\")\n",
    "print(f\"Training feature shape : {train_features.size()}\")\n",
    "print(f\"Training labels shape  : {train_labels.size()}\")\n",
    "print('----------------------------------------------')\n",
    "test_features, test_labels = next(iter(test_loader))\n",
    "print(f\"Test feature shape     : {test_features.size()}\")\n",
    "print(f\"Test labels shape      : {test_labels.size()}\")\n",
    "print(\"===================================================\")\n",
    "print(f\"Lenght train loader: {len(train_loader)}\")\n",
    "print(f\"Lenght test loader: {len(test_loader)}\")\n",
    "print(\"===================================================\")\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Train Features\n",
    "train_image = train_features[0]\n",
    "axes[0].imshow(train_image.permute(1, 2, 0))\n",
    "axes[0].set_title(f\"Train image | Label: {train_labels[0]}\")\n",
    "\n",
    "# Test Features\n",
    "test_image = test_features[0]\n",
    "axes[1].imshow(test_image.permute(1, 2, 0))\n",
    "axes[1].set_title(f\"Test image | Label: {test_labels[0]}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "modelPath = '' # e.g. '/save_path/resnet50/best/resnet50_epoch-1_accT-0.61361_accV-0.56974.pt'\n",
    "isCheckpoint = True\n",
    "\n",
    "if(load_model):\n",
    "  bestAcc, startEpoch = loadModel(modelPath, isCheckpoint=isCheckpoint)\n",
    "else:\n",
    "  bestAcc = 0.00\n",
    "  startEpoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===================================================\")\n",
    "print(F\"The directory for saving checkpoints/models is: {savePath}\")\n",
    "if not(os.path.exists(os.path.join(savePath, 'checkpoint'))):\n",
    "    os.makedirs(os.path.join(savePath, 'checkpoint'))\n",
    "\n",
    "if not(os.path.exists(os.path.join(savePath, 'best'))):\n",
    "    os.makedirs(os.path.join(savePath, 'best'))\n",
    "print(\"===================================================\")\n",
    "\n",
    "trainLosses = []\n",
    "trainAccuracies = []\n",
    "valLosses = []\n",
    "valAccuracies = []\n",
    "    \n",
    "for epoch in range(startEpoch, epochs+1):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    totalTrain = 0\n",
    "    correctTrain = 0\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=F'Epoch {epoch}/{epochs} | Training') as pbar:\n",
    "        for i, data in enumerate(train_loader):\n",
    "            images, labels = data\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            outputs = outputs.view(-1) # Needed for loss computation | Shape [64] instead of [64, 1]\n",
    "            lTrain = criterion(outputs, labels.float())\n",
    "\n",
    "            # Backward and optimize\n",
    "            lTrain.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accuracy\n",
    "            outputs_rounded = (torch.round(outputs)).int()\n",
    "            correctTrain += (outputs_rounded == labels).sum().float()\n",
    "            totalTrain += labels.shape[0]\n",
    "\n",
    "            pbar.update()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correctVal = 0\n",
    "        totalVal = 0\n",
    "        with tqdm(total=len(test_loader), desc=F'Epoch {epoch}/{epochs} | Test') as pbar:\n",
    "            for i, data in enumerate(test_loader):\n",
    "                images, labels = data\n",
    "\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                outputs = outputs.view(-1) # Needed for loss computation | Shape [64] instead of [64, 1]\n",
    "                lVal = criterion(outputs, labels.float())\n",
    "\n",
    "                # Accuracy\n",
    "                outputs_rounded = (torch.round(outputs)).int()\n",
    "                correctVal += (outputs_rounded == labels).sum().float()\n",
    "                totalVal += labels.shape[0]\n",
    "\n",
    "                pbar.update()\n",
    "            \n",
    "    # Losses computation\n",
    "    train_loss_epoch = lTrain.item()\n",
    "    val_loss_epoch = lVal.item()\n",
    "    trainLosses.append(train_loss_epoch)\n",
    "    valLosses.append(val_loss_epoch)\n",
    "    \n",
    "    # Accuracies computation\n",
    "    train_acc_epoch = correctTrain / totalTrain\n",
    "    val_acc_epoch = correctVal / totalVal\n",
    "    trainAccuracies.append(train_acc_epoch.detach().cpu().numpy())\n",
    "    valAccuracies.append(val_acc_epoch.detach().cpu().numpy())\n",
    "\n",
    "    if(val_acc_epoch > bestAcc):\n",
    "        isBest = True\n",
    "        previousBestAcc = bestAcc\n",
    "        bestAcc = val_acc_epoch\n",
    "        print(\"\\nVal Accuracy increased at epoch {}: {:.5f} --> {:.5f} |\".format(epoch, previousBestAcc, bestAcc))\n",
    "    else:\n",
    "        isBest = False\n",
    "\n",
    "    saveModel(state={\n",
    "                    'epoch': epoch,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'train_val': train_acc_epoch,\n",
    "                    'best_val': val_acc_epoch\n",
    "                }, \n",
    "                is_best=isBest)\n",
    "\n",
    "    print('\\nEpoch {}/{}:\\n\\tTrain Acc: {:.3f} (avg. {:.3f}) | Train Loss: {:.3f} (avg. {:.3f}) | \\\n",
    "        \\n\\tVal Acc  : {:.3f} (avg. {:.3f}) | Val Loss: {:.3f} (avg. {:.3f}) |'.format(epoch, epochs, \n",
    "                                                                                    train_acc_epoch*100,\n",
    "                                                                                    np.average(trainAccuracies)*100,  \n",
    "                                                                                    train_loss_epoch,\n",
    "                                                                                    np.average(trainLosses),\n",
    "                                                                                    val_acc_epoch*100,\n",
    "                                                                                    np.average(valAccuracies)*100,\n",
    "                                                                                    val_loss_epoch,\n",
    "                                                                                    np.average(valLosses)))\n",
    "    print(\"=========================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
