{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U tqdm gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies loaded\n",
      "\n",
      "Found GPU: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import gdown\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print('Dependencies loaded.')\n",
    "\n",
    "print(\"===================================================\")\n",
    "if(torch.cuda.is_available()):\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('Cuda available: {}'.format(torch.cuda.is_available()))\n",
    "    print(\"GPU: \" + torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    print(\"Total memory: {:.1f} GB\".format((float(torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)))))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('Cuda not available, so using CPU. Please consider switching to a GPU runtime!')\n",
    "print(\"===================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Download\n",
    "ID = '1wYzBpucuU_RPMebUrWi2TH3Mfz-ykBGl'\n",
    "output = 'Dataset.zip'\n",
    "\n",
    "datasetDirectory = os.path.join(\"Dataset\", \"paperDataset\")\n",
    "if not (os.path.exists(datasetDirectory)):\n",
    "  os.makedirs(datasetDirectory)\n",
    "\n",
    "dataset_url = 'https://drive.google.com/uc?id=' + ID + '&export=download&confirm=t'\n",
    "gdown.download(dataset_url, output, quiet=False)\n",
    "\n",
    "print('Extracting the zipped dataset..')\n",
    "shutil.unpack_archive(\"Dataset.zip\", datasetDirectory)\n",
    "\n",
    "print('Deleting the previous downloaded zip.')\n",
    "os.remove('Dataset.zip')\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gianc\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\gianc\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# Replace the last fully connected layer\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 2)  # 2 for binary classification\n",
    "\n",
    "# Freeze pre-trained layers\n",
    "for n, p in model.named_parameters():\n",
    "    if(n.startswith(\"layer4\") or n.startswith(\"fc\")):\n",
    "        p.requires_grad = True\n",
    "    else:\n",
    "        p.requires_grad = False\n",
    "    #print(F\"Parameter: {n} | Requires grad: {p.requires_grad}\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # Optimizer for training the last layer\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transformations\n",
    "transformTrain = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.CenterCrop(286),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transformsTest = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define paths for train_dir and test_dir according to split perfomed on OFs dataset\n",
    "train_dir = os.path.join(\"Dataset\", \"paperDataset\", \"train\")\n",
    "test_dir = os.path.join(\"Dataset\", \"paperDataset\", \"test\")\n",
    "\n",
    "# Load the custom dataset\n",
    "train_dataset = ImageFolder(root=train_dir, transform=transformTrain)\n",
    "test_dataset = ImageFolder(root=test_dir, transform=transformsTest)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Dataloaders\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(\"===================================================\")\n",
    "print(f\"Training feature shape : {train_features.size()}\")\n",
    "print(f\"Training labels shape  : {train_labels.size()}\")\n",
    "print('----------------------------------------------')\n",
    "test_features, test_labels = next(iter(test_loader))\n",
    "print(f\"Test feature shape     : {test_features.size()}\")\n",
    "print(f\"Test labels shape      : {test_labels.size()}\")\n",
    "print(\"===================================================\")\n",
    "\n",
    "image = train_features[0]\n",
    "plt.imshow(image.permute(1,2,0).clamp(0,1))\n",
    "plt.title(F\"Label: {train_labels[0]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLosses = []\n",
    "trainAccuracies = []\n",
    "valLosses = []\n",
    "valAccuracies = []\n",
    "\n",
    "bestAcc = 0\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    totalTrain = 0\n",
    "    correctTrain = 0\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=F'Epoch {epoch}/{epochs+1} | Training') as pbar:\n",
    "        for i, data in enumerate(train_loader):\n",
    "            images, labels = data\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            lTrain = criterion(outputs, labels)\n",
    "\n",
    "            # Accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            totalTrain += labels.size(0)\n",
    "            correctTrain += (predicted == labels).sum().item()\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            lTrain.backward()\n",
    "            optimizer.step()\n",
    "            pbar.update()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correctVal = 0\n",
    "        totalVal = 0\n",
    "        with tqdm(total=len(test_loader), desc=F'Epoch {epoch}/{epochs+1} | Test') as pbar:\n",
    "            for i, data in enumerate(test_loader):\n",
    "                images, labels = data\n",
    "\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "                lVal = criterion(outputs, labels)\n",
    "\n",
    "                # Accuracy\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                totalVal += labels.size(0)\n",
    "                correctVal += (predicted == labels).sum().item()\n",
    "                pbar.update()\n",
    "            \n",
    "    # Losses computation\n",
    "    train_loss_epoch = lTrain.item()\n",
    "    val_loss_epoch = lVal.item()\n",
    "    trainLosses.append(train_loss_epoch)\n",
    "    valLosses.append(val_loss_epoch)\n",
    "    \n",
    "    # Accuracies computation\n",
    "    val_acc_epoch = correctVal / totalVal\n",
    "    train_acc_epoch = correctTrain / totalTrain\n",
    "    trainAccuracies.append(train_acc_epoch)\n",
    "    valAccuracies.append(val_acc_epoch)\n",
    "\n",
    "    if(val_acc_epoch > bestAcc):\n",
    "        previousBestAcc = bestAcc\n",
    "        bestAcc = val_acc_epoch\n",
    "        print(\"\\nVal Accuracy increased at epoch {}: {:.5f} --> {:.5f} | Saving model..\".format(epoch, previousBestAcc, bestAcc))\n",
    "        torch.save(model, F\"resnet50_epoch-{epoch}_accT-{train_acc_epoch:.5f}_accV-{bestAcc:.5f}.pt\")\n",
    "\n",
    "    print('\\nEpoch {}/{}:\\n\\tTrain Acc: {:.3f} (avg. {:.3f}) | Train Loss: {:.3f} (avg. {:.3f}) | \\\n",
    "        \\n\\tVal Acc  : {:.3f} (avg. {:.3f}) | Val Loss: {:.3f} (avg. {:.3f}) |'.format(epoch, epochs, \n",
    "                                                                                    train_acc_epoch*100,\n",
    "                                                                                    np.average(trainAccuracies)*100,  \n",
    "                                                                                    train_loss_epoch,\n",
    "                                                                                    np.average(trainLosses),\n",
    "                                                                                    val_acc_epoch*100,\n",
    "                                                                                    np.average(valAccuracies)*100,\n",
    "                                                                                    val_loss_epoch,\n",
    "                                                                                    np.average(valLosses)))\n",
    "    print(\"=========================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
